{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recurrent Neural Network\n",
    "\n",
    "\n",
    "\n",
    "# Part 1 - Data Preprocessing\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the training set\n",
    "dataset_train = pd.read_csv('Google_Stock_Price_Train.csv')\n",
    "training_set = dataset_train.iloc[:, 1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/3/2012</td>\n",
       "      <td>325.25</td>\n",
       "      <td>332.83</td>\n",
       "      <td>324.97</td>\n",
       "      <td>663.59</td>\n",
       "      <td>7,380,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2012</td>\n",
       "      <td>331.27</td>\n",
       "      <td>333.87</td>\n",
       "      <td>329.08</td>\n",
       "      <td>666.45</td>\n",
       "      <td>5,749,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/5/2012</td>\n",
       "      <td>329.83</td>\n",
       "      <td>330.75</td>\n",
       "      <td>326.89</td>\n",
       "      <td>657.21</td>\n",
       "      <td>6,590,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/6/2012</td>\n",
       "      <td>328.34</td>\n",
       "      <td>328.77</td>\n",
       "      <td>323.68</td>\n",
       "      <td>648.24</td>\n",
       "      <td>5,405,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/9/2012</td>\n",
       "      <td>322.04</td>\n",
       "      <td>322.29</td>\n",
       "      <td>309.46</td>\n",
       "      <td>620.76</td>\n",
       "      <td>11,688,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1/10/2012</td>\n",
       "      <td>313.70</td>\n",
       "      <td>315.72</td>\n",
       "      <td>307.30</td>\n",
       "      <td>621.43</td>\n",
       "      <td>8,824,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/11/2012</td>\n",
       "      <td>310.59</td>\n",
       "      <td>313.52</td>\n",
       "      <td>309.40</td>\n",
       "      <td>624.25</td>\n",
       "      <td>4,817,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1/12/2012</td>\n",
       "      <td>314.43</td>\n",
       "      <td>315.26</td>\n",
       "      <td>312.08</td>\n",
       "      <td>627.92</td>\n",
       "      <td>3,764,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1/13/2012</td>\n",
       "      <td>311.96</td>\n",
       "      <td>312.30</td>\n",
       "      <td>309.37</td>\n",
       "      <td>623.28</td>\n",
       "      <td>4,631,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1/17/2012</td>\n",
       "      <td>314.81</td>\n",
       "      <td>314.81</td>\n",
       "      <td>311.67</td>\n",
       "      <td>626.86</td>\n",
       "      <td>3,832,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1/18/2012</td>\n",
       "      <td>312.14</td>\n",
       "      <td>315.82</td>\n",
       "      <td>309.90</td>\n",
       "      <td>631.18</td>\n",
       "      <td>5,544,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1/19/2012</td>\n",
       "      <td>319.30</td>\n",
       "      <td>319.30</td>\n",
       "      <td>314.55</td>\n",
       "      <td>637.82</td>\n",
       "      <td>12,657,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1/20/2012</td>\n",
       "      <td>294.16</td>\n",
       "      <td>294.40</td>\n",
       "      <td>289.76</td>\n",
       "      <td>584.39</td>\n",
       "      <td>21,231,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1/23/2012</td>\n",
       "      <td>291.91</td>\n",
       "      <td>293.23</td>\n",
       "      <td>290.49</td>\n",
       "      <td>583.92</td>\n",
       "      <td>6,851,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1/24/2012</td>\n",
       "      <td>292.07</td>\n",
       "      <td>292.74</td>\n",
       "      <td>287.92</td>\n",
       "      <td>579.34</td>\n",
       "      <td>6,134,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1/25/2012</td>\n",
       "      <td>287.68</td>\n",
       "      <td>288.27</td>\n",
       "      <td>282.13</td>\n",
       "      <td>567.93</td>\n",
       "      <td>10,012,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1/26/2012</td>\n",
       "      <td>284.92</td>\n",
       "      <td>286.17</td>\n",
       "      <td>281.22</td>\n",
       "      <td>566.54</td>\n",
       "      <td>6,476,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1/27/2012</td>\n",
       "      <td>284.32</td>\n",
       "      <td>289.08</td>\n",
       "      <td>283.60</td>\n",
       "      <td>578.39</td>\n",
       "      <td>7,262,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1/30/2012</td>\n",
       "      <td>287.95</td>\n",
       "      <td>288.92</td>\n",
       "      <td>285.63</td>\n",
       "      <td>576.11</td>\n",
       "      <td>4,678,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1/31/2012</td>\n",
       "      <td>290.41</td>\n",
       "      <td>290.91</td>\n",
       "      <td>286.50</td>\n",
       "      <td>578.52</td>\n",
       "      <td>4,300,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2/1/2012</td>\n",
       "      <td>291.38</td>\n",
       "      <td>291.66</td>\n",
       "      <td>288.49</td>\n",
       "      <td>579.24</td>\n",
       "      <td>4,658,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2/2/2012</td>\n",
       "      <td>291.34</td>\n",
       "      <td>292.11</td>\n",
       "      <td>289.95</td>\n",
       "      <td>583.51</td>\n",
       "      <td>4,847,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2/3/2012</td>\n",
       "      <td>294.23</td>\n",
       "      <td>297.42</td>\n",
       "      <td>292.93</td>\n",
       "      <td>594.7</td>\n",
       "      <td>6,360,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2/6/2012</td>\n",
       "      <td>296.39</td>\n",
       "      <td>304.27</td>\n",
       "      <td>295.90</td>\n",
       "      <td>607.42</td>\n",
       "      <td>7,386,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2/7/2012</td>\n",
       "      <td>302.44</td>\n",
       "      <td>303.56</td>\n",
       "      <td>300.75</td>\n",
       "      <td>605.11</td>\n",
       "      <td>4,199,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2/8/2012</td>\n",
       "      <td>303.18</td>\n",
       "      <td>304.53</td>\n",
       "      <td>301.24</td>\n",
       "      <td>608.18</td>\n",
       "      <td>3,686,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2/9/2012</td>\n",
       "      <td>304.87</td>\n",
       "      <td>306.10</td>\n",
       "      <td>303.36</td>\n",
       "      <td>609.79</td>\n",
       "      <td>4,546,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2/10/2012</td>\n",
       "      <td>302.81</td>\n",
       "      <td>302.93</td>\n",
       "      <td>300.87</td>\n",
       "      <td>604.25</td>\n",
       "      <td>4,667,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2/13/2012</td>\n",
       "      <td>304.11</td>\n",
       "      <td>305.77</td>\n",
       "      <td>303.87</td>\n",
       "      <td>610.52</td>\n",
       "      <td>3,646,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2/14/2012</td>\n",
       "      <td>304.63</td>\n",
       "      <td>304.86</td>\n",
       "      <td>301.25</td>\n",
       "      <td>608.09</td>\n",
       "      <td>3,620,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>11/17/2016</td>\n",
       "      <td>766.92</td>\n",
       "      <td>772.70</td>\n",
       "      <td>764.23</td>\n",
       "      <td>771.23</td>\n",
       "      <td>1,304,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>11/18/2016</td>\n",
       "      <td>771.37</td>\n",
       "      <td>775.00</td>\n",
       "      <td>760.00</td>\n",
       "      <td>760.54</td>\n",
       "      <td>1,547,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>11/21/2016</td>\n",
       "      <td>762.61</td>\n",
       "      <td>769.70</td>\n",
       "      <td>760.60</td>\n",
       "      <td>769.2</td>\n",
       "      <td>1,330,600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>11/22/2016</td>\n",
       "      <td>772.63</td>\n",
       "      <td>776.96</td>\n",
       "      <td>767.00</td>\n",
       "      <td>768.27</td>\n",
       "      <td>1,593,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>11/23/2016</td>\n",
       "      <td>767.73</td>\n",
       "      <td>768.28</td>\n",
       "      <td>755.25</td>\n",
       "      <td>760.99</td>\n",
       "      <td>1,478,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>11/25/2016</td>\n",
       "      <td>764.26</td>\n",
       "      <td>765.00</td>\n",
       "      <td>760.52</td>\n",
       "      <td>761.68</td>\n",
       "      <td>587,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>11/28/2016</td>\n",
       "      <td>760.00</td>\n",
       "      <td>779.53</td>\n",
       "      <td>759.80</td>\n",
       "      <td>768.24</td>\n",
       "      <td>2,188,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>11/29/2016</td>\n",
       "      <td>771.53</td>\n",
       "      <td>778.50</td>\n",
       "      <td>768.24</td>\n",
       "      <td>770.84</td>\n",
       "      <td>1,616,600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>11/30/2016</td>\n",
       "      <td>770.07</td>\n",
       "      <td>772.99</td>\n",
       "      <td>754.83</td>\n",
       "      <td>758.04</td>\n",
       "      <td>2,392,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>12/1/2016</td>\n",
       "      <td>757.44</td>\n",
       "      <td>759.85</td>\n",
       "      <td>737.03</td>\n",
       "      <td>747.92</td>\n",
       "      <td>3,017,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>12/2/2016</td>\n",
       "      <td>744.59</td>\n",
       "      <td>754.00</td>\n",
       "      <td>743.10</td>\n",
       "      <td>750.5</td>\n",
       "      <td>1,452,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>12/5/2016</td>\n",
       "      <td>757.71</td>\n",
       "      <td>763.90</td>\n",
       "      <td>752.90</td>\n",
       "      <td>762.52</td>\n",
       "      <td>1,394,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>12/6/2016</td>\n",
       "      <td>764.73</td>\n",
       "      <td>768.83</td>\n",
       "      <td>757.34</td>\n",
       "      <td>759.11</td>\n",
       "      <td>1,690,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>12/7/2016</td>\n",
       "      <td>761.00</td>\n",
       "      <td>771.36</td>\n",
       "      <td>755.80</td>\n",
       "      <td>771.19</td>\n",
       "      <td>1,761,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>12/8/2016</td>\n",
       "      <td>772.48</td>\n",
       "      <td>778.18</td>\n",
       "      <td>767.23</td>\n",
       "      <td>776.42</td>\n",
       "      <td>1,488,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>12/9/2016</td>\n",
       "      <td>780.00</td>\n",
       "      <td>789.43</td>\n",
       "      <td>779.02</td>\n",
       "      <td>789.29</td>\n",
       "      <td>1,821,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>12/12/2016</td>\n",
       "      <td>785.04</td>\n",
       "      <td>791.25</td>\n",
       "      <td>784.35</td>\n",
       "      <td>789.27</td>\n",
       "      <td>2,104,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>12/13/2016</td>\n",
       "      <td>793.90</td>\n",
       "      <td>804.38</td>\n",
       "      <td>793.34</td>\n",
       "      <td>796.1</td>\n",
       "      <td>2,145,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>12/14/2016</td>\n",
       "      <td>797.40</td>\n",
       "      <td>804.00</td>\n",
       "      <td>794.01</td>\n",
       "      <td>797.07</td>\n",
       "      <td>1,704,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>12/15/2016</td>\n",
       "      <td>797.34</td>\n",
       "      <td>803.00</td>\n",
       "      <td>792.92</td>\n",
       "      <td>797.85</td>\n",
       "      <td>1,626,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>12/16/2016</td>\n",
       "      <td>800.40</td>\n",
       "      <td>800.86</td>\n",
       "      <td>790.29</td>\n",
       "      <td>790.8</td>\n",
       "      <td>2,443,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>12/19/2016</td>\n",
       "      <td>790.22</td>\n",
       "      <td>797.66</td>\n",
       "      <td>786.27</td>\n",
       "      <td>794.2</td>\n",
       "      <td>1,232,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>12/20/2016</td>\n",
       "      <td>796.76</td>\n",
       "      <td>798.65</td>\n",
       "      <td>793.27</td>\n",
       "      <td>796.42</td>\n",
       "      <td>951,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>12/21/2016</td>\n",
       "      <td>795.84</td>\n",
       "      <td>796.68</td>\n",
       "      <td>787.10</td>\n",
       "      <td>794.56</td>\n",
       "      <td>1,211,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>12/22/2016</td>\n",
       "      <td>792.36</td>\n",
       "      <td>793.32</td>\n",
       "      <td>788.58</td>\n",
       "      <td>791.26</td>\n",
       "      <td>972,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>12/23/2016</td>\n",
       "      <td>790.90</td>\n",
       "      <td>792.74</td>\n",
       "      <td>787.28</td>\n",
       "      <td>789.91</td>\n",
       "      <td>623,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>12/27/2016</td>\n",
       "      <td>790.68</td>\n",
       "      <td>797.86</td>\n",
       "      <td>787.66</td>\n",
       "      <td>791.55</td>\n",
       "      <td>789,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>12/28/2016</td>\n",
       "      <td>793.70</td>\n",
       "      <td>794.23</td>\n",
       "      <td>783.20</td>\n",
       "      <td>785.05</td>\n",
       "      <td>1,153,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>12/29/2016</td>\n",
       "      <td>783.33</td>\n",
       "      <td>785.93</td>\n",
       "      <td>778.92</td>\n",
       "      <td>782.79</td>\n",
       "      <td>744,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>12/30/2016</td>\n",
       "      <td>782.75</td>\n",
       "      <td>782.78</td>\n",
       "      <td>770.41</td>\n",
       "      <td>771.82</td>\n",
       "      <td>1,770,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1258 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    Open    High     Low   Close      Volume\n",
       "0       1/3/2012  325.25  332.83  324.97  663.59   7,380,500\n",
       "1       1/4/2012  331.27  333.87  329.08  666.45   5,749,400\n",
       "2       1/5/2012  329.83  330.75  326.89  657.21   6,590,300\n",
       "3       1/6/2012  328.34  328.77  323.68  648.24   5,405,900\n",
       "4       1/9/2012  322.04  322.29  309.46  620.76  11,688,800\n",
       "5      1/10/2012  313.70  315.72  307.30  621.43   8,824,000\n",
       "6      1/11/2012  310.59  313.52  309.40  624.25   4,817,800\n",
       "7      1/12/2012  314.43  315.26  312.08  627.92   3,764,400\n",
       "8      1/13/2012  311.96  312.30  309.37  623.28   4,631,800\n",
       "9      1/17/2012  314.81  314.81  311.67  626.86   3,832,800\n",
       "10     1/18/2012  312.14  315.82  309.90  631.18   5,544,000\n",
       "11     1/19/2012  319.30  319.30  314.55  637.82  12,657,800\n",
       "12     1/20/2012  294.16  294.40  289.76  584.39  21,231,800\n",
       "13     1/23/2012  291.91  293.23  290.49  583.92   6,851,300\n",
       "14     1/24/2012  292.07  292.74  287.92  579.34   6,134,400\n",
       "15     1/25/2012  287.68  288.27  282.13  567.93  10,012,700\n",
       "16     1/26/2012  284.92  286.17  281.22  566.54   6,476,500\n",
       "17     1/27/2012  284.32  289.08  283.60  578.39   7,262,000\n",
       "18     1/30/2012  287.95  288.92  285.63  576.11   4,678,400\n",
       "19     1/31/2012  290.41  290.91  286.50  578.52   4,300,700\n",
       "20      2/1/2012  291.38  291.66  288.49  579.24   4,658,700\n",
       "21      2/2/2012  291.34  292.11  289.95  583.51   4,847,400\n",
       "22      2/3/2012  294.23  297.42  292.93   594.7   6,360,700\n",
       "23      2/6/2012  296.39  304.27  295.90  607.42   7,386,700\n",
       "24      2/7/2012  302.44  303.56  300.75  605.11   4,199,700\n",
       "25      2/8/2012  303.18  304.53  301.24  608.18   3,686,400\n",
       "26      2/9/2012  304.87  306.10  303.36  609.79   4,546,300\n",
       "27     2/10/2012  302.81  302.93  300.87  604.25   4,667,700\n",
       "28     2/13/2012  304.11  305.77  303.87  610.52   3,646,100\n",
       "29     2/14/2012  304.63  304.86  301.25  608.09   3,620,900\n",
       "...          ...     ...     ...     ...     ...         ...\n",
       "1228  11/17/2016  766.92  772.70  764.23  771.23   1,304,000\n",
       "1229  11/18/2016  771.37  775.00  760.00  760.54   1,547,100\n",
       "1230  11/21/2016  762.61  769.70  760.60   769.2   1,330,600\n",
       "1231  11/22/2016  772.63  776.96  767.00  768.27   1,593,100\n",
       "1232  11/23/2016  767.73  768.28  755.25  760.99   1,478,400\n",
       "1233  11/25/2016  764.26  765.00  760.52  761.68     587,400\n",
       "1234  11/28/2016  760.00  779.53  759.80  768.24   2,188,200\n",
       "1235  11/29/2016  771.53  778.50  768.24  770.84   1,616,600\n",
       "1236  11/30/2016  770.07  772.99  754.83  758.04   2,392,900\n",
       "1237   12/1/2016  757.44  759.85  737.03  747.92   3,017,900\n",
       "1238   12/2/2016  744.59  754.00  743.10   750.5   1,452,500\n",
       "1239   12/5/2016  757.71  763.90  752.90  762.52   1,394,200\n",
       "1240   12/6/2016  764.73  768.83  757.34  759.11   1,690,700\n",
       "1241   12/7/2016  761.00  771.36  755.80  771.19   1,761,000\n",
       "1242   12/8/2016  772.48  778.18  767.23  776.42   1,488,100\n",
       "1243   12/9/2016  780.00  789.43  779.02  789.29   1,821,900\n",
       "1244  12/12/2016  785.04  791.25  784.35  789.27   2,104,100\n",
       "1245  12/13/2016  793.90  804.38  793.34   796.1   2,145,200\n",
       "1246  12/14/2016  797.40  804.00  794.01  797.07   1,704,200\n",
       "1247  12/15/2016  797.34  803.00  792.92  797.85   1,626,500\n",
       "1248  12/16/2016  800.40  800.86  790.29   790.8   2,443,800\n",
       "1249  12/19/2016  790.22  797.66  786.27   794.2   1,232,100\n",
       "1250  12/20/2016  796.76  798.65  793.27  796.42     951,000\n",
       "1251  12/21/2016  795.84  796.68  787.10  794.56   1,211,300\n",
       "1252  12/22/2016  792.36  793.32  788.58  791.26     972,200\n",
       "1253  12/23/2016  790.90  792.74  787.28  789.91     623,400\n",
       "1254  12/27/2016  790.68  797.86  787.66  791.55     789,100\n",
       "1255  12/28/2016  793.70  794.23  783.20  785.05   1,153,800\n",
       "1256  12/29/2016  783.33  785.93  778.92  782.79     744,300\n",
       "1257  12/30/2016  782.75  782.78  770.41  771.82   1,770,000\n",
       "\n",
       "[1258 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[325.25],\n",
       "       [331.27],\n",
       "       [329.83],\n",
       "       ...,\n",
       "       [793.7 ],\n",
       "       [783.33],\n",
       "       [782.75]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08581368],\n",
       "       [0.09701243],\n",
       "       [0.09433366],\n",
       "       ...,\n",
       "       [0.95725128],\n",
       "       [0.93796041],\n",
       "       [0.93688146]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a data structure with 60 timesteps and 1 output\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(60, 1258):\n",
    "    X_train.append(training_set_scaled[i-60:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08581368, 0.09701243, 0.09433366, ..., 0.07846566, 0.08034452,\n",
       "        0.08497656],\n",
       "       [0.09701243, 0.09433366, 0.09156187, ..., 0.08034452, 0.08497656,\n",
       "        0.08627874],\n",
       "       [0.09433366, 0.09156187, 0.07984225, ..., 0.08497656, 0.08627874,\n",
       "        0.08471612],\n",
       "       ...,\n",
       "       [0.92106928, 0.92438053, 0.93048218, ..., 0.95475854, 0.95204256,\n",
       "        0.95163331],\n",
       "       [0.92438053, 0.93048218, 0.9299055 , ..., 0.95204256, 0.95163331,\n",
       "        0.95725128],\n",
       "       [0.93048218, 0.9299055 , 0.93113327, ..., 0.95163331, 0.95725128,\n",
       "        0.93796041]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1198, 60)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.08581368],\n",
       "        [0.09701243],\n",
       "        [0.09433366],\n",
       "        ...,\n",
       "        [0.07846566],\n",
       "        [0.08034452],\n",
       "        [0.08497656]],\n",
       "\n",
       "       [[0.09701243],\n",
       "        [0.09433366],\n",
       "        [0.09156187],\n",
       "        ...,\n",
       "        [0.08034452],\n",
       "        [0.08497656],\n",
       "        [0.08627874]],\n",
       "\n",
       "       [[0.09433366],\n",
       "        [0.09156187],\n",
       "        [0.07984225],\n",
       "        ...,\n",
       "        [0.08497656],\n",
       "        [0.08627874],\n",
       "        [0.08471612]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.92106928],\n",
       "        [0.92438053],\n",
       "        [0.93048218],\n",
       "        ...,\n",
       "        [0.95475854],\n",
       "        [0.95204256],\n",
       "        [0.95163331]],\n",
       "\n",
       "       [[0.92438053],\n",
       "        [0.93048218],\n",
       "        [0.9299055 ],\n",
       "        ...,\n",
       "        [0.95204256],\n",
       "        [0.95163331],\n",
       "        [0.95725128]],\n",
       "\n",
       "       [[0.93048218],\n",
       "        [0.9299055 ],\n",
       "        [0.93113327],\n",
       "        ...,\n",
       "        [0.95163331],\n",
       "        [0.95725128],\n",
       "        [0.93796041]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Part 2 - Building the RNN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 1))\n",
    "\n",
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 - Making the predictions and visualising the results\n",
    "\n",
    "# Getting the real stock price of 2017\n",
    "dataset_test = pd.read_csv('Google_Stock_Price_Test.csv')\n",
    "real_stock_price = dataset_test.iloc[:, 1:2].values\n",
    "\n",
    "# Getting the predicted stock price of 2017\n",
    "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = sc.transform(inputs)\n",
    "X_test = []\n",
    "for i in range(60, 80):\n",
    "    X_test.append(inputs[i-60:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "predicted_stock_price = regressor.predict(X_test)\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the results\n",
    "plt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\n",
    "plt.title('Google Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Google Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
